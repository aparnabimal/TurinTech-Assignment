{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aparnabimal/TurinTech-Assignment/main.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 194>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aparnabimal/TurinTech-Assignment/main.ipynb#W0sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aparnabimal/TurinTech-Assignment/main.ipynb#W0sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m \u001b[39m# Assume 'y' is your target variable\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/aparnabimal/TurinTech-Assignment/main.ipynb#W0sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mThe_average_annual_payroll_of_the_region\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aparnabimal/TurinTech-Assignment/main.ipynb#W0sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39m# Split the real data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/aparnabimal/TurinTech-Assignment/main.ipynb#W0sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m X_train_real, X_test_real, y_train_real, y_test_real \u001b[39m=\u001b[39m train_test_split(data, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "# url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv('Month_Value_1.csv')\n",
    "\n",
    "# Standardize the data (important for GANs)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "num_features = scaled_data.shape[1]\n",
    "\n",
    "# Retain column names\n",
    "column_names = data.columns\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset(scaled_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Define the generator loss\n",
    "def generator_loss(D_G_z):\n",
    "    return -torch.mean(D_G_z)\n",
    "\n",
    "# Define the discriminator loss\n",
    "def discriminator_loss(D_x, D_G_z):\n",
    "    return -(torch.mean(D_x) - torch.mean(D_G_z))\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.0001\n",
    "betas = (0.5, 0.9)\n",
    "batch_size = 64\n",
    "n_epochs = 50\n",
    "threshold = 0.5\n",
    "lambda_reg = 0.1\n",
    "\n",
    "class AugmentedFilterLayer(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(AugmentedFilterLayer, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, x, Gz):\n",
    "        distance = torch.sqrt(torch.sum((x - Gz)**2, dim=1))\n",
    "        return torch.where(distance.unsqueeze(-1) < self.threshold, Gz, torch.zeros_like(Gz))\n",
    "\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 256), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh(),  \n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    \n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Create the Generator and the Discriminator\n",
    "input_dim = 100\n",
    "output_dim = num_features\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(input_dim, output_dim).to(device)\n",
    "discriminator = Discriminator(output_dim).to(device)\n",
    "\n",
    "# optimizers\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "# Augmented Filter Layer\n",
    "augmented_filter_layer = AugmentedFilterLayer(threshold)\n",
    "\n",
    "# Define the TRH distance calculation function\n",
    "def calculate_TRH_distance(XT, YT, lambda_reg):\n",
    "    # Step 1: Generate the matrix D_lambda\n",
    "    k, m = XT.size(0), YT.size(0)\n",
    "    D_lambda = torch.empty(k, m)\n",
    "    for i in range(k):\n",
    "        for j in range(m):\n",
    "            d = torch.norm(XT[i] - YT[j]) + lambda_reg * abs(i - j)\n",
    "            D_lambda[i, j] = d\n",
    "\n",
    "    # Step 2: Calculate dx and dy\n",
    "    dx = torch.min(D_lambda, dim=1)[0]\n",
    "    dy = torch.min(D_lambda, dim=0)[0]\n",
    "\n",
    "    # Step 3: Calculate dx_max and dy_max\n",
    "    dx_max = torch.max(dx)\n",
    "    dy_max = torch.max(dy)\n",
    "\n",
    "    # Step 4: Calculate d_trh\n",
    "    d_trh = max(dx_max, dy_max)\n",
    "\n",
    "    return d_trh\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        real_data = data.to(device)\n",
    "        \n",
    "        # ====== Train Discriminator ====== #\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # Generate fake data and detach (so gradients are not calculated for generator)\n",
    "        noise = torch.randn(batch_size, input_dim, device=device)\n",
    "        fake_data = generator(noise)\n",
    "        fake_data = augmented_filter_layer(real_data, fake_data.detach())\n",
    "        \n",
    "        # Calculate TRH distance\n",
    "        trh_distance = calculate_TRH_distance(real_data, fake_data, lambda_reg)\n",
    "        \n",
    "        # Forward pass real and fake batches through Discriminator\n",
    "        D_x = discriminator(real_data)\n",
    "        D_G_z = discriminator(fake_data)\n",
    "        \n",
    "        # Calculate Discriminator loss\n",
    "        d_loss = discriminator_loss(D_x, D_G_z)\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # ====== Train Generator ====== #\n",
    "        optimizerG.zero_grad()\n",
    "        \n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise)\n",
    "        fake_data = augmented_filter_layer(real_data, fake_data)\n",
    "\n",
    "        # Calculate TRH distance\n",
    "        trh_distance = calculate_TRH_distance(real_data, fake_data, lambda_reg)\n",
    "\n",
    "        # Forward pass fake batch through Discriminator\n",
    "        D_G_z = discriminator(fake_data)\n",
    "        \n",
    "        # Calculate Generator loss\n",
    "        g_loss = generator_loss(D_G_z)\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "# Generate some data\n",
    "z = torch.randn((batch_size, input_dim)).to(device)\n",
    "generated_data = generator(z).detach().cpu().numpy()\n",
    "\n",
    "# Apply inverse transform to recover original scale\n",
    "generated_data = scaler.inverse_transform(generated_data)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assume 'y' is your target variable\n",
    "y = data['The_average_annual_payroll_of_the_region']\n",
    "\n",
    "# Split the real data\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the generated data\n",
    "X_train_gen, X_test_gen, y_train_gen, y_test_gen = train_test_split(generated_data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Weighted Logistic Regression Model for real data\n",
    "model_real = LogisticRegression(class_weight='balanced')\n",
    "model_real.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Weighted Logistic Regression Model for generated data\n",
    "model_gen = LogisticRegression(class_weight='balanced')\n",
    "model_gen.fit(X_train_gen, y_train_gen)\n",
    "\n",
    "# Evaluate the models\n",
    "score_real = model_real.score(X_test_real, y_test_real)\n",
    "score_gen = model_gen.score(X_test_gen, y_test_gen)\n",
    "\n",
    "print(\"Real data score:\", score_real)\n",
    "print(\"Generated data score:\", score_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
